{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c93249-6b0e-46f0-a7dc-71dffffa8476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train and validation datasets for hyperparameter tuning.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load train and validation datasets to use all available labeled data for tuning\n",
    "train_path = \"/home/danial/Data Science/Churn Prediction/Data/Splitted/train.csv\"\n",
    "val_path = \"/home/danial/Data Science/Churn Prediction/Data/Splitted/val.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "# Combine train and validation for better hyperparameter search coverage\n",
    "full_train = pd.concat([train_df, val_df], axis=0)\n",
    "\n",
    "X_full = full_train.drop(columns=[\"Churn\"])\n",
    "y_full = full_train[\"Churn\"]\n",
    "\n",
    "print(\"Combined train and validation datasets for hyperparameter tuning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b23936-af58-4080-949e-19200cbf92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined parameter grids for Logistic Regression and Decision Tree.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define search space for Logistic Regression\n",
    "logreg_params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\"],\n",
    "    \"max_iter\": [100, 200, 500]\n",
    "}\n",
    "\n",
    "# Define search space for Decision Tree\n",
    "tree_params = {\n",
    "    \"max_depth\": [3, 5, 7, 10, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "print(\"Defined parameter grids for Logistic Regression and Decision Tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656ea9d6-62c0-4c7b-a072-e2045a56e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: {'clf__C': 0.001, 'clf__max_iter': 100, 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Build pipeline: scaling + logistic regression\n",
    "logreg_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# Set up GridSearchCV for Logistic Regression\n",
    "logreg_grid = GridSearchCV(\n",
    "    estimator=logreg_pipe,\n",
    "    param_grid={\n",
    "        \"clf__C\": logreg_params[\"C\"],\n",
    "        \"clf__solver\": logreg_params[\"solver\"],\n",
    "        \"clf__max_iter\": logreg_params[\"max_iter\"]\n",
    "    },\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "logreg_grid.fit(X_full, y_full)\n",
    "\n",
    "print(\"Best Logistic Regression Params:\", logreg_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a89560-2641-44a4-9051-99f8cb231b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Params: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Set up GridSearchCV for Decision Tree\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "tree_grid = GridSearchCV(\n",
    "    estimator=tree_clf,\n",
    "    param_grid=tree_params,\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "tree_grid.fit(X_full, y_full)\n",
    "\n",
    "print(\"Best Decision Tree Params:\", tree_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc392a0-51a5-46ec-99d9-82c4685c60ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final models retrained with best hyperparameters.\n"
     ]
    }
   ],
   "source": [
    "# Retrain Logistic Regression with best params on full train data\n",
    "best_logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        C=logreg_grid.best_params_[\"clf__C\"],\n",
    "        solver=logreg_grid.best_params_[\"clf__solver\"],\n",
    "        max_iter=logreg_grid.best_params_[\"clf__max_iter\"]\n",
    "    ))\n",
    "])\n",
    "best_logreg.fit(X_full, y_full)\n",
    "\n",
    "# Retrain Decision Tree with best params on full train data\n",
    "best_tree = DecisionTreeClassifier(**tree_grid.best_params_, random_state=42)\n",
    "best_tree.fit(X_full, y_full)\n",
    "\n",
    "print(\"Final models retrained with best hyperparameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ea6bab-d5c3-41a0-a3f6-77593f6e70c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Logistic Regression - Test\n",
      "Accuracy : 0.7886524822695036\n",
      "Precision: 0.5979381443298969\n",
      "Recall   : 0.6203208556149733\n",
      "F1-Score : 0.6089238845144357\n",
      "ROC-AUC  : 0.7348708525179113\n",
      "\n",
      "Tuned Decision Tree - Test\n",
      "Accuracy : 0.750354609929078\n",
      "Precision: 0.526829268292683\n",
      "Recall   : 0.5775401069518716\n",
      "F1-Score : 0.5510204081632653\n",
      "ROC-AUC  : 0.6951407098465923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load test set\n",
    "test_path = \"/home/danial/Data Science/Churn Prediction/Data/Splitted/test.csv\"\n",
    "test_df = pd.read_csv(test_path)\n",
    "X_test = test_df.drop(columns=[\"Churn\"])\n",
    "y_test = test_df[\"Churn\"]\n",
    "\n",
    "# Make predictions with tuned models\n",
    "log_test_pred = best_logreg.predict(X_test)\n",
    "tree_test_pred = best_tree.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "def evaluate(y_true, y_pred, name):\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred))\n",
    "    print(\"F1-Score :\", f1_score(y_true, y_pred))\n",
    "    print(\"ROC-AUC  :\", roc_auc_score(y_true, y_pred))\n",
    "\n",
    "evaluate(y_test, log_test_pred, \"Tuned Logistic Regression - Test\")\n",
    "evaluate(y_test, tree_test_pred, \"Tuned Decision Tree - Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f627f55-8791-4425-b400-3b74a4c2b91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cpenv)",
   "language": "python",
   "name": "cpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
