{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaf82954-4639-4262-a9e7-769d39da6fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after removing ChurnFlag: ['SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'MonthlyCharges', 'TotalCharges', 'ChargeDiff', 'ChargeDiffPerc', 'NumServices', 'HasInternet', 'InternetService_Fiber optic', 'InternetService_No', 'Contract_One year', 'Contract_Two year', 'PaymentMethod_Credit card (automatic)', 'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check', 'Churn', 'tenure_group_12-24', 'tenure_group_24-48', 'tenure_group_48+']\n",
      "Dataset shape: (7043, 30)\n",
      "\n",
      "Target distribution:\n",
      "Churn\n",
      "0    0.73463\n",
      "1    0.26537\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Load the preprocessed dataset and inspect target distribution ---\n",
    "import pandas as pd\n",
    "\n",
    "# Load the final preprocessed dataset\n",
    "final_path = \"/home/danial/Data Science/Churn Prediction/Data/Processed/final_preprocessed.csv\"\n",
    "df = pd.read_csv(final_path)\n",
    "\n",
    "# Drop leaky column\n",
    "df = df.drop(columns=['ChurnFlag'], errors='ignore')\n",
    "\n",
    "# Confirm removal\n",
    "print(\"Columns after removing ChurnFlag:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "# Check the shape and class distribution\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['Churn'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fafb4588-4f11-4136-94d3-36d142039826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (5634, 29) Temp size: (1409, 29)\n",
      "Train target distribution:\n",
      " Churn\n",
      "0    0.734647\n",
      "1    0.265353\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: First split into Train and Temp (Validation+Test) with stratification ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']\n",
    "\n",
    "# Split: 80% Train, 20% Temp (Validation+Test), keeping class balance\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Temp size:\", X_temp.shape)\n",
    "print(\"Train target distribution:\\n\", y_train.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c2d7b28-9c7a-46bc-8d59-3474c6995d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: (704, 29) Test size: (705, 29)\n",
      "Validation target distribution:\n",
      " Churn\n",
      "0    0.734375\n",
      "1    0.265625\n",
      "Name: proportion, dtype: float64\n",
      "Test target distribution:\n",
      " Churn\n",
      "0    0.734752\n",
      "1    0.265248\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Split Temp into Validation and Test sets ---\n",
    "# Now split the 20% Temp equally into Validation and Test (10% each of the original dataset)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Validation size:\", X_val.shape, \"Test size:\", X_test.shape)\n",
    "print(\"Validation target distribution:\\n\", y_val.value_counts(normalize=True))\n",
    "print(\"Test target distribution:\\n\", y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c91b8f0d-0042-4f49-a79f-4c6fbfe9dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between Train and Validation: 0\n",
      "Overlap between Train and Test: 0\n",
      "Overlap between Validation and Test: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Check for potential data leakage (duplicate rows across splits) ---\n",
    "# Concatenate indices for each split and check overlaps\n",
    "train_idx = set(X_train.index)\n",
    "val_idx = set(X_val.index)\n",
    "test_idx = set(X_test.index)\n",
    "\n",
    "overlap_train_val = train_idx.intersection(val_idx)\n",
    "overlap_train_test = train_idx.intersection(test_idx)\n",
    "overlap_val_test = val_idx.intersection(test_idx)\n",
    "\n",
    "print(\"Overlap between Train and Validation:\", len(overlap_train_val))\n",
    "print(\"Overlap between Train and Test:\", len(overlap_train_test))\n",
    "print(\"Overlap between Validation and Test:\", len(overlap_val_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6800c0f0-d0ee-43c1-af12-4c4d13451b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved successfully:\n",
      "/home/danial/Data Science/Churn Prediction/Data/Splitted/train.csv /home/danial/Data Science/Churn Prediction/Data/Splitted/val.csv /home/danial/Data Science/Churn Prediction/Data/Splitted/test.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Save the splits for later use ---\n",
    "train_path = \"/home/danial/Data Science/Churn Prediction/Data/Splitted/train.csv\"\n",
    "val_path = \"/home/danial/Data Science/Churn Prediction/Data/Splitted/val.csv\"\n",
    "test_path = \"/home/danial/Data Science/Churn Prediction/Data/Splitted/test.csv\"\n",
    "\n",
    "X_train.assign(Churn=y_train).to_csv(train_path, index=False)\n",
    "X_val.assign(Churn=y_val).to_csv(val_path, index=False)\n",
    "X_test.assign(Churn=y_test).to_csv(test_path, index=False)\n",
    "\n",
    "print(\"Datasets saved successfully:\")\n",
    "print(train_path, val_path, test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2c722-b2d2-4029-920c-5b1cc0689e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cpenv)",
   "language": "python",
   "name": "cpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
